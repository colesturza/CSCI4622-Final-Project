{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model\n",
    "\n",
    "The first model I'd like to try is a KNN model. I expect that this model will perform the worst out of the four models I've decided to create. This is becasue... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/fma_metadata/'\n",
    "tracks = pd.read_csv(path + 'tracks.csv', index_col=0, header=[0, 1])\n",
    "features = pd.read_csv(path + 'features.csv', index_col=0, header=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve all of the features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 training examples\n",
      "800 cross validation examples\n",
      "800 testing examples\n",
      "20 features, 8 classes\n"
     ]
    }
   ],
   "source": [
    "# This code is selecting the small dataset and extracting the features to use in the model.\n",
    "# It is also separating the tracks into train, validation, and test sets.\n",
    "small = tracks['set', 'subset'] == 'small'\n",
    "\n",
    "# FMA has already separated the tracks for into the three sets (train, val, test)\n",
    "train = tracks['set', 'split'] == 'training'\n",
    "val = tracks['set', 'split'] == 'validation'\n",
    "test = tracks['set', 'split'] == 'test'\n",
    "\n",
    "# Load the genre labels\n",
    "y_train = tracks.loc[small & train, ('track', 'genre_top')]\n",
    "y_val = tracks.loc[small & val, ('track', 'genre_top')]\n",
    "y_test = tracks.loc[small & test, ('track', 'genre_top')]\n",
    "\n",
    "# Load the mfccs and convert to a numpy ndarray, I am only going to use the means for now.\n",
    "# We have 20 MFCCs. When using the mfcc function in librosa, which FMA uses to get all the feature \n",
    "# statisitcs, it will return an array. From what I've see in a bunch of articles and papers people\n",
    "# generally take the mean of each column and use the vector of means as 20 features. This is what I\n",
    "# will do as well.\n",
    "X_train_mfcc = features.loc[small & train, 'mfcc']['mean']\n",
    "X_val_mfcc = features.loc[small & val, 'mfcc']['mean']\n",
    "X_test_mfcc = features.loc[small & test, 'mfcc']['mean']\n",
    "\n",
    "print('{} training examples'.format(y_train.size))\n",
    "print('{} cross validation examples'.format(y_val.size))\n",
    "print('{} testing examples'.format(y_test.size))\n",
    "print('{} features, {} classes'.format(X_train_mfcc.shape[1], np.unique(y_train).size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In music, the term chroma feature or chromagram closely relates to the twelve different pitch classes. This could be a useful feature because different types of music likely may use different pitches more frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_chroma_cens = features.loc[small & train, 'chroma_cens']['mean']\n",
    "X_val_chroma_cens = features.loc[small & val, 'chroma_cens']['mean']\n",
    "X_test_chroma_cens = features.loc[small & test, 'chroma_cens']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_mfcc, X_train_chroma_cens], axis=1, sort=False)\n",
    "X_val = pd.concat([X_val_mfcc, X_val_chroma_cens], axis=1, sort=False)\n",
    "X_test = pd.concat([X_test_mfcc, X_test_chroma_cens], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more features\n",
    "\n",
    "Now that I've performed PCA on the MFCCs I'd like to add a couple more features to the model. The features that I'm going to be adding are the Spectral Centroid, Spectral Rolloff, Zero Crossing Rate, RMSE, Spectral Bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>number</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>spectral_rolloff</th>\n",
       "      <th>zcr</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-163.772964</td>\n",
       "      <td>116.696678</td>\n",
       "      <td>-41.753826</td>\n",
       "      <td>29.144329</td>\n",
       "      <td>-15.050158</td>\n",
       "      <td>18.879372</td>\n",
       "      <td>-8.918165</td>\n",
       "      <td>12.002118</td>\n",
       "      <td>-4.253151</td>\n",
       "      <td>1.359791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248795</td>\n",
       "      <td>0.196245</td>\n",
       "      <td>0.175809</td>\n",
       "      <td>0.200713</td>\n",
       "      <td>0.319972</td>\n",
       "      <td>1639.583252</td>\n",
       "      <td>1607.474365</td>\n",
       "      <td>3267.804688</td>\n",
       "      <td>0.085629</td>\n",
       "      <td>3.188761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-205.440491</td>\n",
       "      <td>132.215073</td>\n",
       "      <td>-16.085823</td>\n",
       "      <td>41.514759</td>\n",
       "      <td>-7.642954</td>\n",
       "      <td>16.942802</td>\n",
       "      <td>-5.651261</td>\n",
       "      <td>9.569445</td>\n",
       "      <td>0.503157</td>\n",
       "      <td>8.673513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293982</td>\n",
       "      <td>0.346324</td>\n",
       "      <td>0.289821</td>\n",
       "      <td>0.246368</td>\n",
       "      <td>0.220939</td>\n",
       "      <td>1292.958130</td>\n",
       "      <td>1512.917358</td>\n",
       "      <td>2773.931885</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>3.251386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-135.864822</td>\n",
       "      <td>157.040085</td>\n",
       "      <td>-53.453247</td>\n",
       "      <td>17.198896</td>\n",
       "      <td>6.868035</td>\n",
       "      <td>13.934344</td>\n",
       "      <td>-11.749298</td>\n",
       "      <td>8.360711</td>\n",
       "      <td>-5.130381</td>\n",
       "      <td>0.233845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349137</td>\n",
       "      <td>0.268424</td>\n",
       "      <td>0.243144</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.236763</td>\n",
       "      <td>1360.028687</td>\n",
       "      <td>1420.259644</td>\n",
       "      <td>2603.491943</td>\n",
       "      <td>0.077515</td>\n",
       "      <td>3.893810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-225.713318</td>\n",
       "      <td>139.332825</td>\n",
       "      <td>-13.097699</td>\n",
       "      <td>44.533356</td>\n",
       "      <td>2.468400</td>\n",
       "      <td>28.328743</td>\n",
       "      <td>-9.931481</td>\n",
       "      <td>10.810857</td>\n",
       "      <td>3.002879</td>\n",
       "      <td>-0.937692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191970</td>\n",
       "      <td>0.291551</td>\n",
       "      <td>0.319938</td>\n",
       "      <td>0.198516</td>\n",
       "      <td>0.120607</td>\n",
       "      <td>1232.633789</td>\n",
       "      <td>1475.625366</td>\n",
       "      <td>2583.014160</td>\n",
       "      <td>0.052379</td>\n",
       "      <td>2.953848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-253.143906</td>\n",
       "      <td>155.716324</td>\n",
       "      <td>-16.636627</td>\n",
       "      <td>23.683815</td>\n",
       "      <td>6.045957</td>\n",
       "      <td>11.692952</td>\n",
       "      <td>-9.947761</td>\n",
       "      <td>6.887814</td>\n",
       "      <td>-3.273322</td>\n",
       "      <td>-6.340906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181313</td>\n",
       "      <td>0.177233</td>\n",
       "      <td>0.296048</td>\n",
       "      <td>0.331963</td>\n",
       "      <td>0.218315</td>\n",
       "      <td>941.244141</td>\n",
       "      <td>1192.835571</td>\n",
       "      <td>1905.394531</td>\n",
       "      <td>0.040267</td>\n",
       "      <td>2.576761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "number            01          02         03         04         05         06  \\\n",
       "track_id                                                                       \n",
       "2        -163.772964  116.696678 -41.753826  29.144329 -15.050158  18.879372   \n",
       "5        -205.440491  132.215073 -16.085823  41.514759  -7.642954  16.942802   \n",
       "10       -135.864822  157.040085 -53.453247  17.198896   6.868035  13.934344   \n",
       "140      -225.713318  139.332825 -13.097699  44.533356   2.468400  28.328743   \n",
       "141      -253.143906  155.716324 -16.636627  23.683815   6.045957  11.692952   \n",
       "\n",
       "number           07         08        09        10  ...        08        09  \\\n",
       "track_id                                            ...                       \n",
       "2         -8.918165  12.002118 -4.253151  1.359791  ...  0.248795  0.196245   \n",
       "5         -5.651261   9.569445  0.503157  8.673513  ...  0.293982  0.346324   \n",
       "10       -11.749298   8.360711 -5.130381  0.233845  ...  0.349137  0.268424   \n",
       "140       -9.931481  10.810857  3.002879 -0.937692  ...  0.191970  0.291551   \n",
       "141       -9.947761   6.887814 -3.273322 -6.340906  ...  0.181313  0.177233   \n",
       "\n",
       "number          10        11        12  spectral_centroid  spectral_bandwidth  \\\n",
       "track_id                                                                        \n",
       "2         0.175809  0.200713  0.319972        1639.583252         1607.474365   \n",
       "5         0.289821  0.246368  0.220939        1292.958130         1512.917358   \n",
       "10        0.243144  0.268941  0.236763        1360.028687         1420.259644   \n",
       "140       0.319938  0.198516  0.120607        1232.633789         1475.625366   \n",
       "141       0.296048  0.331963  0.218315         941.244141         1192.835571   \n",
       "\n",
       "number    spectral_rolloff       zcr      rmse  \n",
       "track_id                                        \n",
       "2              3267.804688  0.085629  3.188761  \n",
       "5              2773.931885  0.053114  3.251386  \n",
       "10             2603.491943  0.077515  3.893810  \n",
       "140            2583.014160  0.052379  2.953848  \n",
       "141            1905.394531  0.040267  2.576761  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = ['spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff', 'zcr', 'rmse']\n",
    "for feat in feats:\n",
    "    X_train[feat] = features.loc[small & train, feat]['mean']\n",
    "    X_val[feat] = features.loc[small & val, feat]['mean']\n",
    "    X_test[feat] = features.loc[small & test, feat]['mean']\n",
    "    \n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine train and validation data\n",
    "\n",
    "I'm doing this becasue I am going to use a gridsearch with K-fold crossvalidation. Therefore, there is no need for a crossvalidation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200 training examples\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.concat([X_train, X_val], axis=0, sort=False)\n",
    "y_train = pd.concat([y_train, y_val], axis=0, sort=False)\n",
    "\n",
    "print('{} training examples'.format(y_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_sc = scaler.transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'weights': ('uniform', 'distance'), 'n_neighbors': range(15, 31)}\n",
    "neigh = KNeighborsClassifier()\n",
    "clf = GridSearchCV(neigh, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'n_neighbors': range(15, 31),\n",
       "                         'weights': ('uniform', 'distance')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_neighbors': 22, 'weights': 'distance'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.373 (+/-0.052) for {'n_neighbors': 15, 'weights': 'uniform'}\n",
      "0.376 (+/-0.051) for {'n_neighbors': 15, 'weights': 'distance'}\n",
      "0.371 (+/-0.049) for {'n_neighbors': 16, 'weights': 'uniform'}\n",
      "0.375 (+/-0.053) for {'n_neighbors': 16, 'weights': 'distance'}\n",
      "0.376 (+/-0.054) for {'n_neighbors': 17, 'weights': 'uniform'}\n",
      "0.380 (+/-0.051) for {'n_neighbors': 17, 'weights': 'distance'}\n",
      "0.379 (+/-0.053) for {'n_neighbors': 18, 'weights': 'uniform'}\n",
      "0.380 (+/-0.054) for {'n_neighbors': 18, 'weights': 'distance'}\n",
      "0.382 (+/-0.054) for {'n_neighbors': 19, 'weights': 'uniform'}\n",
      "0.380 (+/-0.053) for {'n_neighbors': 19, 'weights': 'distance'}\n",
      "0.383 (+/-0.055) for {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "0.385 (+/-0.052) for {'n_neighbors': 20, 'weights': 'distance'}\n",
      "0.382 (+/-0.056) for {'n_neighbors': 21, 'weights': 'uniform'}\n",
      "0.389 (+/-0.049) for {'n_neighbors': 21, 'weights': 'distance'}\n",
      "0.383 (+/-0.058) for {'n_neighbors': 22, 'weights': 'uniform'}\n",
      "0.389 (+/-0.048) for {'n_neighbors': 22, 'weights': 'distance'}\n",
      "0.386 (+/-0.056) for {'n_neighbors': 23, 'weights': 'uniform'}\n",
      "0.389 (+/-0.046) for {'n_neighbors': 23, 'weights': 'distance'}\n",
      "0.381 (+/-0.054) for {'n_neighbors': 24, 'weights': 'uniform'}\n",
      "0.385 (+/-0.048) for {'n_neighbors': 24, 'weights': 'distance'}\n",
      "0.381 (+/-0.057) for {'n_neighbors': 25, 'weights': 'uniform'}\n",
      "0.387 (+/-0.054) for {'n_neighbors': 25, 'weights': 'distance'}\n",
      "0.381 (+/-0.055) for {'n_neighbors': 26, 'weights': 'uniform'}\n",
      "0.387 (+/-0.054) for {'n_neighbors': 26, 'weights': 'distance'}\n",
      "0.381 (+/-0.056) for {'n_neighbors': 27, 'weights': 'uniform'}\n",
      "0.387 (+/-0.047) for {'n_neighbors': 27, 'weights': 'distance'}\n",
      "0.384 (+/-0.056) for {'n_neighbors': 28, 'weights': 'uniform'}\n",
      "0.387 (+/-0.046) for {'n_neighbors': 28, 'weights': 'distance'}\n",
      "0.385 (+/-0.057) for {'n_neighbors': 29, 'weights': 'uniform'}\n",
      "0.389 (+/-0.049) for {'n_neighbors': 29, 'weights': 'distance'}\n",
      "0.384 (+/-0.060) for {'n_neighbors': 30, 'weights': 'uniform'}\n",
      "0.388 (+/-0.049) for {'n_neighbors': 30, 'weights': 'distance'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Electronic       0.00      0.00      0.00       100\n",
      " Experimental       0.12      0.90      0.21       100\n",
      "         Folk       0.00      0.00      0.00       100\n",
      "      Hip-Hop       0.00      0.00      0.00       100\n",
      " Instrumental       0.00      0.00      0.00       100\n",
      "International       0.03      0.01      0.01       100\n",
      "          Pop       0.00      0.00      0.00       100\n",
      "         Rock       0.00      0.00      0.00       100\n",
      "\n",
      "     accuracy                           0.11       800\n",
      "    macro avg       0.02      0.11      0.03       800\n",
      " weighted avg       0.02      0.11      0.03       800\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cole/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
