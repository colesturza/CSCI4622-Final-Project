<<<<<<< HEAD
{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"cnn.ipynb","provenance":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"wSYnM804viei","colab_type":"text"},"source":["## Convolutional Neural Network"]},{"cell_type":"code","metadata":{"id":"D48Qwxt5viek","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers.normalization import BatchNormalization\n","from keras import optimizers\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Lgb-RM9vies","colab_type":"text"},"source":["## Retrieve all of the features and labels"]},{"cell_type":"code","metadata":{"id":"BJtny1Rtvsn9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"3827f161-7c0b-4d68-c83c-c0318b53bff4","executionInfo":{"status":"ok","timestamp":1588447212961,"user_tz":360,"elapsed":19014,"user":{"displayName":"Cole Sturza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCVXhcj9IhKIE5NvQOYwcD7wMRdrpofXbBdtLt=s64","userId":"03613262892583477283"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OUnGHZOKviet","colab_type":"code","colab":{}},"source":["npzfile = np.load('drive/My Drive/CSCI/CSCI4622/data/melspects_128.npz', allow_pickle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IpqooHf0viez","colab_type":"code","colab":{}},"source":["X_train, y_train = npzfile['X_train'], npzfile['y_train']\n","X_test, y_test = npzfile['X_test'], npzfile['y_test']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tgl66ALLvie3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"70e4a62f-e5ef-4336-9e88-cf5572a8bb97","executionInfo":{"status":"ok","timestamp":1588447220813,"user_tz":360,"elapsed":291,"user":{"displayName":"Cole Sturza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCVXhcj9IhKIE5NvQOYwcD7wMRdrpofXbBdtLt=s64","userId":"03613262892583477283"}}},"source":["X_test.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 128, 640)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"uxpQgE84vie8","colab_type":"text"},"source":["## Building the Neural Net"]},{"cell_type":"code","metadata":{"id":"RV-SHiZpvie9","colab_type":"code","colab":{}},"source":["def CNN(X_shape, nb_classes):\n","    \n","    # Input\n","    inputs = Input(shape=X_shape)\n","    \n","    conv1 = Conv2D(filters=32, kernel_size=(2,2), strides=1, padding='valid', \n","                   activation='relu')(inputs)\n","    \n","    b1 = BatchNormalization()(conv1)\n","    \n","    pool1 = MaxPooling2D((2, 2), strides=(2, 2))(b1)\n","    \n","    conv2 = Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='valid', \n","                   activation='relu')(pool1)\n","    \n","    pool2 = MaxPooling2D((3, 3), strides=(3, 3))(conv2)\n","    \n","    dr1 = Dropout(0.2)(pool2)\n","    \n","    conv3 = Conv2D(filters=64, kernel_size=(2,2), strides=1, padding='valid', \n","                   activation='relu')(dr1)\n","    \n","    b2 = BatchNormalization()(conv3)\n","    \n","    pool3 = MaxPooling2D((2, 2), strides=(2, 4))(b2)\n","\n","    dr2 = Dropout(0.2)(pool3)\n","    \n","    flatten = Flatten()(dr2)\n","    \n","    dense1 = Dense(64, activation='relu')(flatten)\n","    \n","    dense2 = Dense(32, activation='relu')(dense1)\n","    \n","    # Softmax Output\n","    output = Dense(nb_classes, activation='softmax')(dense2)\n","    \n","    model_output = output\n","    model = Model(inputs=inputs, outputs=[output])\n","    \n","    opt = optimizers.Adagrad(learning_rate=0.001)\n","    model.compile(loss='kullback_leibler_divergence', optimizer=opt, metrics=['accuracy'])\n","    \n","    print(model.summary())\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IbTXjlKevifB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b7296756-8423-4713-9359-d8921b725dfa","executionInfo":{"status":"ok","timestamp":1588453511211,"user_tz":360,"elapsed":730076,"user":{"displayName":"Cole Sturza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCVXhcj9IhKIE5NvQOYwcD7wMRdrpofXbBdtLt=s64","userId":"03613262892583477283"}}},"source":["nb_classes = len(np.unique(y_train))\n","nb_epochs = 75\n","batch_size = 2\n","\n","# Convert to one hot encoding\n","y_train_one_hot = np.zeros((y_train.size, nb_classes))\n","y_train_one_hot[range(y_train.size),y_train] = 1\n","\n","# Need to add a channel dim for the convolution layers\n","X_train_expanded = np.expand_dims(X_train, axis=-1)\n","X_test_expanded = np.expand_dims(X_test, axis=-1)\n","\n","X_shape = X_train_expanded.shape[1:]\n","\n","model = CNN(X_shape, nb_classes)\n","\n","# Fit data to model\n","history = model.fit(X_train_expanded, y_train_one_hot, batch_size=batch_size, \n","                    epochs=nb_epochs, validation_split=0.2)"],"execution_count":63,"outputs":[{"output_type":"stream","text":["Model: \"model_22\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_22 (InputLayer)        (None, 128, 640, 1)       0         \n","_________________________________________________________________\n","conv2d_64 (Conv2D)           (None, 127, 639, 32)      160       \n","_________________________________________________________________\n","batch_normalization_43 (Batc (None, 127, 639, 32)      128       \n","_________________________________________________________________\n","max_pooling2d_64 (MaxPooling (None, 63, 319, 32)       0         \n","_________________________________________________________________\n","conv2d_65 (Conv2D)           (None, 61, 317, 64)       18496     \n","_________________________________________________________________\n","max_pooling2d_65 (MaxPooling (None, 20, 105, 64)       0         \n","_________________________________________________________________\n","dropout_31 (Dropout)         (None, 20, 105, 64)       0         \n","_________________________________________________________________\n","conv2d_66 (Conv2D)           (None, 19, 104, 64)       16448     \n","_________________________________________________________________\n","batch_normalization_44 (Batc (None, 19, 104, 64)       256       \n","_________________________________________________________________\n","max_pooling2d_66 (MaxPooling (None, 9, 26, 64)         0         \n","_________________________________________________________________\n","dropout_32 (Dropout)         (None, 9, 26, 64)         0         \n","_________________________________________________________________\n","flatten_22 (Flatten)         (None, 14976)             0         \n","_________________________________________________________________\n","dense_66 (Dense)             (None, 64)                958528    \n","_________________________________________________________________\n","dense_67 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_68 (Dense)             (None, 10)                330       \n","=================================================================\n","Total params: 996,426\n","Trainable params: 996,234\n","Non-trainable params: 192\n","_________________________________________________________________\n","None\n","Train on 720 samples, validate on 180 samples\n","Epoch 1/75\n","720/720 [==============================] - 10s 14ms/step - loss: 2.2340 - accuracy: 0.2389 - val_loss: 1.9993 - val_accuracy: 0.2722\n","Epoch 2/75\n","720/720 [==============================] - 10s 13ms/step - loss: 1.7868 - accuracy: 0.3833 - val_loss: 1.9043 - val_accuracy: 0.3444\n","Epoch 3/75\n","720/720 [==============================] - 10s 13ms/step - loss: 1.6128 - accuracy: 0.4403 - val_loss: 1.6788 - val_accuracy: 0.4444\n","Epoch 4/75\n","720/720 [==============================] - 10s 14ms/step - loss: 1.4146 - accuracy: 0.5222 - val_loss: 1.6114 - val_accuracy: 0.4722\n","Epoch 5/75\n","720/720 [==============================] - 10s 14ms/step - loss: 1.2560 - accuracy: 0.5778 - val_loss: 1.6458 - val_accuracy: 0.4333\n","Epoch 6/75\n","720/720 [==============================] - 10s 14ms/step - loss: 1.1197 - accuracy: 0.6417 - val_loss: 1.5592 - val_accuracy: 0.4556\n","Epoch 7/75\n","720/720 [==============================] - 10s 14ms/step - loss: 1.0998 - accuracy: 0.6347 - val_loss: 1.4793 - val_accuracy: 0.4833\n","Epoch 8/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.9616 - accuracy: 0.6778 - val_loss: 1.4047 - val_accuracy: 0.5000\n","Epoch 9/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.8688 - accuracy: 0.7083 - val_loss: 1.4414 - val_accuracy: 0.4722\n","Epoch 10/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.7845 - accuracy: 0.7528 - val_loss: 1.3884 - val_accuracy: 0.5222\n","Epoch 11/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.7599 - accuracy: 0.7458 - val_loss: 1.3693 - val_accuracy: 0.4889\n","Epoch 12/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.7271 - accuracy: 0.7806 - val_loss: 1.3850 - val_accuracy: 0.4889\n","Epoch 13/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.6261 - accuracy: 0.7958 - val_loss: 1.3502 - val_accuracy: 0.5278\n","Epoch 14/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.6248 - accuracy: 0.8111 - val_loss: 1.3167 - val_accuracy: 0.5167\n","Epoch 15/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.5558 - accuracy: 0.8361 - val_loss: 1.3408 - val_accuracy: 0.5056\n","Epoch 16/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.4595 - accuracy: 0.8931 - val_loss: 1.3191 - val_accuracy: 0.5500\n","Epoch 17/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.4442 - accuracy: 0.8931 - val_loss: 1.3183 - val_accuracy: 0.5333\n","Epoch 18/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.4083 - accuracy: 0.8903 - val_loss: 1.3190 - val_accuracy: 0.5333\n","Epoch 19/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.3710 - accuracy: 0.9111 - val_loss: 1.3208 - val_accuracy: 0.5444\n","Epoch 20/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.3445 - accuracy: 0.9139 - val_loss: 1.3072 - val_accuracy: 0.5278\n","Epoch 21/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.3344 - accuracy: 0.9097 - val_loss: 1.3285 - val_accuracy: 0.5222\n","Epoch 22/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.3352 - accuracy: 0.9208 - val_loss: 1.2966 - val_accuracy: 0.5222\n","Epoch 23/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.2818 - accuracy: 0.9389 - val_loss: 1.2805 - val_accuracy: 0.5333\n","Epoch 24/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.2664 - accuracy: 0.9472 - val_loss: 1.2944 - val_accuracy: 0.5222\n","Epoch 25/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.2820 - accuracy: 0.9417 - val_loss: 1.3088 - val_accuracy: 0.5278\n","Epoch 26/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.2526 - accuracy: 0.9472 - val_loss: 1.2662 - val_accuracy: 0.5333\n","Epoch 27/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.2558 - accuracy: 0.9417 - val_loss: 1.2910 - val_accuracy: 0.5333\n","Epoch 28/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.2268 - accuracy: 0.9556 - val_loss: 1.2792 - val_accuracy: 0.5333\n","Epoch 29/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.1977 - accuracy: 0.9639 - val_loss: 1.3129 - val_accuracy: 0.5167\n","Epoch 30/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.1908 - accuracy: 0.9667 - val_loss: 1.3251 - val_accuracy: 0.5111\n","Epoch 31/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.1881 - accuracy: 0.9667 - val_loss: 1.2804 - val_accuracy: 0.5389\n","Epoch 32/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.1811 - accuracy: 0.9681 - val_loss: 1.2868 - val_accuracy: 0.5333\n","Epoch 33/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.1611 - accuracy: 0.9736 - val_loss: 1.2990 - val_accuracy: 0.5111\n","Epoch 34/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.1670 - accuracy: 0.9736 - val_loss: 1.3184 - val_accuracy: 0.5222\n","Epoch 35/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.1402 - accuracy: 0.9861 - val_loss: 1.2907 - val_accuracy: 0.5222\n","Epoch 36/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.1424 - accuracy: 0.9778 - val_loss: 1.3173 - val_accuracy: 0.5000\n","Epoch 37/75\n","720/720 [==============================] - 9s 13ms/step - loss: 0.1461 - accuracy: 0.9819 - val_loss: 1.2938 - val_accuracy: 0.5222\n","Epoch 38/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.1408 - accuracy: 0.9722 - val_loss: 1.2909 - val_accuracy: 0.5167\n","Epoch 39/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.1333 - accuracy: 0.9764 - val_loss: 1.2934 - val_accuracy: 0.5278\n","Epoch 40/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.1257 - accuracy: 0.9819 - val_loss: 1.3302 - val_accuracy: 0.5222\n","Epoch 41/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.1273 - accuracy: 0.9861 - val_loss: 1.3128 - val_accuracy: 0.5389\n","Epoch 42/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.1068 - accuracy: 0.9931 - val_loss: 1.3125 - val_accuracy: 0.5222\n","Epoch 43/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.1198 - accuracy: 0.9806 - val_loss: 1.3009 - val_accuracy: 0.5222\n","Epoch 44/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.1033 - accuracy: 0.9944 - val_loss: 1.3200 - val_accuracy: 0.5056\n","Epoch 45/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.1090 - accuracy: 0.9847 - val_loss: 1.3241 - val_accuracy: 0.5056\n","Epoch 46/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.1033 - accuracy: 0.9875 - val_loss: 1.3223 - val_accuracy: 0.5167\n","Epoch 47/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.0950 - accuracy: 0.9889 - val_loss: 1.3013 - val_accuracy: 0.5278\n","Epoch 48/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0912 - accuracy: 0.9875 - val_loss: 1.3148 - val_accuracy: 0.5056\n","Epoch 49/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.0875 - accuracy: 0.9917 - val_loss: 1.3011 - val_accuracy: 0.5167\n","Epoch 50/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0923 - accuracy: 0.9861 - val_loss: 1.3334 - val_accuracy: 0.5222\n","Epoch 51/75\n","720/720 [==============================] - 9s 13ms/step - loss: 0.0853 - accuracy: 0.9889 - val_loss: 1.3253 - val_accuracy: 0.5333\n","Epoch 52/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0914 - accuracy: 0.9861 - val_loss: 1.2998 - val_accuracy: 0.5500\n","Epoch 53/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.0803 - accuracy: 0.9903 - val_loss: 1.3166 - val_accuracy: 0.5389\n","Epoch 54/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.0902 - accuracy: 0.9847 - val_loss: 1.3156 - val_accuracy: 0.5278\n","Epoch 55/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.0711 - accuracy: 0.9958 - val_loss: 1.3243 - val_accuracy: 0.5333\n","Epoch 56/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0661 - accuracy: 0.9958 - val_loss: 1.3218 - val_accuracy: 0.5278\n","Epoch 57/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0639 - accuracy: 0.9972 - val_loss: 1.3061 - val_accuracy: 0.5333\n","Epoch 58/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0669 - accuracy: 0.9917 - val_loss: 1.2944 - val_accuracy: 0.5556\n","Epoch 59/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0698 - accuracy: 0.9889 - val_loss: 1.2919 - val_accuracy: 0.5444\n","Epoch 60/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0726 - accuracy: 0.9917 - val_loss: 1.3193 - val_accuracy: 0.5222\n","Epoch 61/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0687 - accuracy: 0.9875 - val_loss: 1.2786 - val_accuracy: 0.5444\n","Epoch 62/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0717 - accuracy: 0.9861 - val_loss: 1.2997 - val_accuracy: 0.5444\n","Epoch 63/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0700 - accuracy: 0.9903 - val_loss: 1.2989 - val_accuracy: 0.5222\n","Epoch 64/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0611 - accuracy: 0.9903 - val_loss: 1.3404 - val_accuracy: 0.5167\n","Epoch 65/75\n","720/720 [==============================] - 9s 13ms/step - loss: 0.0572 - accuracy: 0.9931 - val_loss: 1.3065 - val_accuracy: 0.5389\n","Epoch 66/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0541 - accuracy: 0.9931 - val_loss: 1.3335 - val_accuracy: 0.5167\n","Epoch 67/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.0546 - accuracy: 0.9958 - val_loss: 1.3115 - val_accuracy: 0.5167\n","Epoch 68/75\n","720/720 [==============================] - 10s 14ms/step - loss: 0.0526 - accuracy: 0.9958 - val_loss: 1.3344 - val_accuracy: 0.5167\n","Epoch 69/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0491 - accuracy: 0.9972 - val_loss: 1.3194 - val_accuracy: 0.5167\n","Epoch 70/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0538 - accuracy: 0.9986 - val_loss: 1.3417 - val_accuracy: 0.5167\n","Epoch 71/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0532 - accuracy: 0.9944 - val_loss: 1.3125 - val_accuracy: 0.5222\n","Epoch 72/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0506 - accuracy: 0.9944 - val_loss: 1.3207 - val_accuracy: 0.5167\n","Epoch 73/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0559 - accuracy: 0.9931 - val_loss: 1.3186 - val_accuracy: 0.5389\n","Epoch 74/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0617 - accuracy: 0.9903 - val_loss: 1.3511 - val_accuracy: 0.5222\n","Epoch 75/75\n","720/720 [==============================] - 10s 13ms/step - loss: 0.0560 - accuracy: 0.9917 - val_loss: 1.3434 - val_accuracy: 0.5278\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OfApAbTcvifG","colab_type":"code","colab":{}},"source":["preds = model.predict(X_test_expanded)\n","y_pred = np.argmax(preds, axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rGUQwZbavifN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":306},"outputId":"f133b929-1395-4ec9-9d91-05e5607717b1","executionInfo":{"status":"ok","timestamp":1588453519465,"user_tz":360,"elapsed":350,"user":{"displayName":"Cole Sturza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCVXhcj9IhKIE5NvQOYwcD7wMRdrpofXbBdtLt=s64","userId":"03613262892583477283"}}},"source":["print(classification_report(y_test, y_pred))"],"execution_count":65,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.40      0.50      0.44        12\n","           1       0.69      0.69      0.69        13\n","           2       0.50      0.30      0.37        10\n","           3       0.50      0.80      0.62         5\n","           4       0.62      0.83      0.71         6\n","           5       0.57      0.87      0.68        15\n","           6       0.62      0.80      0.70        10\n","           7       0.40      0.22      0.29         9\n","           8       1.00      0.21      0.35        14\n","           9       0.33      0.33      0.33         6\n","\n","    accuracy                           0.55       100\n","   macro avg       0.56      0.56      0.52       100\n","weighted avg       0.59      0.55      0.52       100\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HbjqsyGvNUel","colab_type":"code","colab":{}},"source":["matrix = confusion_matrix(y_test, y_pred)"],"execution_count":0,"outputs":[]}]}
=======
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve all of the features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('../data/melspects.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = npzfile['X_train'], npzfile['y_train']\n",
    "X_test, y_test = npzfile['X_test'], npzfile['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 96, 640)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(X_shape, nb_classes):\n",
    "    \n",
    "    # Input\n",
    "    inputs = Input(shape=X_shape)\n",
    "    \n",
    "    conv1 = Conv2D(filters=64, kernel_size=(4,4), strides=1, padding='valid', \n",
    "                   activation='relu')(inputs)\n",
    "    \n",
    "    b1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling2D((2, 4), strides=(2, 4))(b1)\n",
    "    \n",
    "    conv2 = Conv2D(filters=64, kernel_size=(3,5), strides=1, padding='valid', \n",
    "                   activation='relu')(pool1)\n",
    "    \n",
    "    pool2 = MaxPooling2D((2, 2), strides=(2, 2))(conv2)\n",
    "    \n",
    "    dr1 = Dropout(0.2)(pool2)\n",
    "    \n",
    "    conv3 = Conv2D(filters=64, kernel_size=(2,2), strides=1, padding='valid', \n",
    "                   activation='relu')(dr1)\n",
    "    \n",
    "    b2 = BatchNormalization()(conv3)\n",
    "    \n",
    "    pool3 = MaxPooling2D((2, 2), strides=(2, 4))(b2)\n",
    "    \n",
    "    flatten = Flatten()(pool3)\n",
    "    \n",
    "    dense1 = Dense(64, activation='relu')(flatten)\n",
    "    \n",
    "    dense2 = Dense(32, activation='relu')(dense1)\n",
    "    \n",
    "    # Softmax Output\n",
    "    output = Dense(nb_classes, activation='softmax')(dense2)\n",
    "    \n",
    "    model_output = output\n",
    "    model = Model(inputs=inputs, outputs=[output])\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 640, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 93, 637, 64)       1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 93, 637, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 46, 159, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 155, 64)       61504     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 77, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 22, 77, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 76, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 21, 76, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12160)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                778304    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 860,266\n",
      "Trainable params: 860,010\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 675 samples, validate on 75 samples\n",
      "Epoch 1/25\n"
     ]
    }
   ],
   "source": [
    "nb_classes = len(np.unique(y_train))\n",
    "nb_epochs = 25\n",
    "batch_size = 128\n",
    "\n",
    "# Convert to one hot encoding\n",
    "y_train_one_hot = np.zeros((y_train.size, nb_classes))\n",
    "y_train_one_hot[range(y_train.size),y_train] = 1\n",
    "\n",
    "# Need to add a channel dim for the convolution layers\n",
    "X_train_expanded = np.expand_dims(X_train, axis=-1)\n",
    "X_test_expanded = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "X_shape = X_train_expanded.shape[1:]\n",
    "\n",
    "model = CNN(X_shape, nb_classes)\n",
    "\n",
    "# Fit data to model\n",
    "history = model.fit(X_train_expanded, y_train_one_hot, batch_size=batch_size, \n",
    "                    epochs=nb_epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test_expanded)\n",
    "y_pred = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.35      0.38        26\n",
      "           1       1.00      0.31      0.47        29\n",
      "           2       0.33      0.43      0.38        23\n",
      "           3       0.64      0.36      0.46        25\n",
      "           4       0.44      0.85      0.58        27\n",
      "           5       0.52      0.56      0.54        25\n",
      "           6       0.86      0.86      0.86        22\n",
      "           7       0.86      0.43      0.57        28\n",
      "           8       0.29      0.48      0.36        21\n",
      "           9       0.37      0.42      0.39        24\n",
      "\n",
      "    accuracy                           0.50       250\n",
      "   macro avg       0.58      0.50      0.50       250\n",
      "weighted avg       0.59      0.50      0.50       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
>>>>>>> 359ca95bd502098a855ff517f172a0a0545273be
