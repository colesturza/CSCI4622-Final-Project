{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model\n",
    "\n",
    "The first model I'd like to try is a KNN model. I expect that this model will perform the worst out of the four models I've decided to create. This is becasue... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/fma_metadata/'\n",
    "tracks = pd.read_csv(path + 'tracks.csv', index_col=0, header=[0, 1])\n",
    "features = pd.read_csv(path + 'features.csv', index_col=0, header=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve all of the features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 training examples\n",
      "800 cross validation examples\n",
      "800 testing examples\n",
      "20 features, 8 classes\n"
     ]
    }
   ],
   "source": [
    "# This code is selecting the small dataset and extracting the features to use in the model.\n",
    "# It is also separating the tracks into train, validation, and test sets.\n",
    "small = tracks['set', 'subset'] == 'small'\n",
    "\n",
    "# FMA has already separated the tracks for into the three sets (train, val, test)\n",
    "train = tracks['set', 'split'] == 'training'\n",
    "val = tracks['set', 'split'] == 'validation'\n",
    "test = tracks['set', 'split'] == 'test'\n",
    "\n",
    "# Load the genre labels\n",
    "y_train = tracks.loc[small & train, ('track', 'genre_top')]\n",
    "y_val = tracks.loc[small & val, ('track', 'genre_top')]\n",
    "y_test = tracks.loc[small & test, ('track', 'genre_top')]\n",
    "\n",
    "# Load the mfccs and convert to a numpy ndarray, I am only going to use the means for now.\n",
    "# We have 20 MFCCs. When using the mfcc function in librosa, which FMA uses to get all the feature \n",
    "# statisitcs, it will return an array. From what I've see in a bunch of articles and papers people\n",
    "# generally take the mean of each column and use the vector of means as 20 features. This is what I\n",
    "# will do as well.\n",
    "X_train_mfcc = features.loc[small & train, 'mfcc']['mean'].to_numpy()\n",
    "X_val_mfcc = features.loc[small & val, 'mfcc']['mean'].to_numpy()\n",
    "X_test_mfcc = features.loc[small & test, 'mfcc']['mean'].to_numpy()\n",
    "\n",
    "print('{} training examples'.format(y_train.size))\n",
    "print('{} cross validation examples'.format(y_val.size))\n",
    "print('{} testing examples'.format(y_test.size))\n",
    "print('{} features, {} classes'.format(X_train_mfcc.shape[1], np.unique(y_train).size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more features\n",
    "\n",
    "Now that I've performed PCA on the MFCCs I'd like to add a couple more features to the model. The features that I'm going to be adding are the Spectral Centroid, Spectral Rolloff, Zero Crossing Rate, RMSE, Spectral Bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the mfccs and convert to a numpy ndarray\n",
    "X_train_zcr = features.loc[small & train, 'zcr']['mean'].to_numpy()\n",
    "X_val_zcr = features.loc[small & val, 'zcr']['mean'].to_numpy()\n",
    "X_test_zcr = features.loc[small & test, 'zcr']['mean'].to_numpy()\n",
    "\n",
    "X_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
